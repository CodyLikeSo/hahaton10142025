from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams, Distance
import openai
import json
from collections import Counter
import re

from config import KEYWORDS_SET, format_input


embed = openai.Client(
    base_url="https://llm.t1v.scibox.tech/v1", api_key="sk-iXC2N_CPmS97ROX9ZXLDTw"
)
qdrant = QdrantClient(url="http://localhost:52068")
model = "bge-m3"
COLLECTION_NAME = "somebody_once_told_me"
CSV_PATH = "./data.csv"
import csv


def _hash(x: str) -> int:
    return x.__hash__() & ((1 << 64) - 1)


def get_embedding(text: str) -> list[float]:
    response = embed.embeddings.create(model=model, input=text)
    return response.data[0].embedding


def get_embedding_batch(text: list[str]) -> list[tuple[str, list[float]]]:
    response = embed.embeddings.create(model=model, input=text)
    return zip(text, [x.embedding for x in response.data])


def search(text: str, take: int) -> list[dict]:
    query_vector = get_embedding(text)
    try:
        search_result = qdrant.search(
            collection_name=COLLECTION_NAME,
            query_vector=query_vector,
            limit=take,
        )
        results = []
        for p in search_result:
            result = {
                "id": p.id,
                "score": p.score,
                "payload": p.payload,
            }
            results.append(result)
        return results
    except Exception as e:
        return json.dumps({"error": str(e)})


def search_in_qdrant(query: str, limit: int = 5) -> list[dict]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫: –≤–µ–∫—Ç–æ—Ä–Ω—ã–π + –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ final_score = 0.7*vector + 0.3*keyword.
    """


    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–ø—Ä–æ—Å
    query_lower = format_input(query)

    # –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä –∏ –¥–µ–ª–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
    vector = get_embedding(query)
    try:
        hits = qdrant.search(
            collection_name=COLLECTION_NAME, query_vector=vector, limit=limit * 2  # –±–µ—Ä—ë–º —á—É—Ç—å –±–æ–ª—å—à–µ –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞
        )
    except Exception as e:
        return [{"error": str(e)}]

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º —Å–∫–æ—Ä–æ–º
    results = []
    for hit in hits:
        payload = hit.payload

        # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ payload –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        # –ú–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å –∏ –≤–æ–ø—Ä–æ—Å, –∏ –æ—Ç–≤–µ—Ç ‚Äî –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–≤–æ–µ–π –∑–∞–¥–∞—á–∏
        doc_text = " ".join([
            payload.get("–ü—Ä–∏–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞", ""),
            payload.get("–®–∞–±–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç", ""),
            payload.get("–û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è", ""),
            payload.get("–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è", "")
        ]).lower()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞

        query_keywords = {kw for kw in KEYWORDS_SET if kw in query_lower}
        doc_keywords = {kw for kw in KEYWORDS_SET if kw in doc_text}

        # –°—á–∏—Ç–∞–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
        overlap = query_keywords & doc_keywords

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º keyword_match_score
        if query_keywords:
            keyword_score = len(overlap) / len(query_keywords)
        else:
            keyword_score = 0.0

        vector_score = hit.score  # –æ–±—ã—á–Ω–æ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1] –¥–ª—è cosine
        final_score = 0.88 * vector_score + 0.12 * keyword_score

        results.append({
            "id": hit.id,
            "vector_score": vector_score,
            "keyword_score": keyword_score,
            "final_score": final_score,
            "payload": payload
        })

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ final_score –ø–æ —É–±—ã–≤–∞–Ω–∏—é
    results.sort(key=lambda x: x["final_score"], reverse=True)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ top `limit` —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
    return [
        {
            "id": r["id"],
            "score": r["final_score"],  # –∏–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å vector_score ‚Äî –Ω–æ –ª—É—á—à–µ final
            "payload": r["payload"]
        }
        for r in results[:limit]
    ]


def upsert(text: str):
    p = PointStruct(id=_hash(text), vector=get_embedding(text), payload={"txt": text})
    qdrant.upsert(COLLECTION_NAME, [p])


def upsert_batch(text: list[str]):
    p = [
        PointStruct(id=_hash(t), vector=e, payload={"txt": t})
        for t, e in get_embedding_batch(text)
    ]
    qdrant.upsert(COLLECTION_NAME, p)


def insert_batch_from_csv():
    questions = []
    payloads = []
    with open(CSV_PATH, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            question = row.get("–ü—Ä–∏–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞", "").strip()
            if not question:
                continue
            questions.append(question)
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –í–ï–°–¨ —Ä—è–¥ –∫–∞–∫ payload
            payloads.append(row)

    if not questions:
        print("no items to insert")
        return

    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    embeddings = [e for _, e in get_embedding_batch(questions)]

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–æ—á–∫–∏ —Å –ø–æ–ª–Ω—ã–º payload
    points = [
        PointStruct(id=_hash(q), vector=emb, payload=payload)
        for q, emb, payload in zip(questions, embeddings, payloads)
    ]
    qdrant.upsert(COLLECTION_NAME, points)


def create_collection():
    qdrant.recreate_collection(
        COLLECTION_NAME,
        vectors_config=VectorParams(
            distance=Distance.COSINE,
            size=1024,
        ),
    )


# === –ó–∞–ø—É—Å–∫ ===
def init_qdrant():
    print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Qdrant...")

    qdrant.recreate_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=VectorParams(size=1024, distance=Distance.COSINE),
    )

    questions = []
    payloads = []
    with open(CSV_PATH, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            question = row.get("–ü—Ä–∏–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞", "").strip()
            if question:
                questions.append(question)
                payloads.append(row)

    if not questions:
        print("‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
        return

    embeddings = [e for _, e in get_embedding_batch(questions)]
    points = [
        PointStruct(id=_hash(q), vector=emb, payload=payload)
        for q, emb, payload in zip(questions, embeddings, payloads)
    ]
    qdrant.upsert(collection_name=COLLECTION_NAME, points=points)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(points)} –∑–∞–ø–∏—Å–µ–π –≤ Qdrant")


# print("inserted")
# print(search("rm -rf /*", 3))
# print(search("drop db", 10))

# qdrant = QdrantClient(url="http://localhost:5433", api_key="drop-database")
# qdrant.create_collection(
#     collection_name="somebody_once_told_me"
# )

# SUPPORTED_EMBEDDING_MODELS = {'bge-m3'}
# qdrant.set_model("bge-m3", providers=embed)
# result = embed.embeddings.create([
#     "how to drop database",
#     "help me connecting to bank",
#     "i downloaded ios app and it not working. hellp me please i am loosing money!",
#     "the world is gonna roll me",
#     "POSTGRES POSTGRES POSTGRES POSTGRES",
#     "hmm"
# ], model="bge-m3");
# points = [
#     PointStruct(
#         id=7,
#         vector=data.embedding,
#         payload={"text": text},
#     )
#     for idx, (data, text) in enumerate(zip(result.data, texts))
# ]
# qdrant.upsert("somebody_once_told_me", )
# qdrant.add(
#     "somebody_once_told_me",
#     [
#         "how to drop database",
#         "help me connecting to bank",
#         "i downloaded ios app and it not working. hellp me please i am loosing money!",
#         "the world is gonna roll me",
#         "POSTGRES POSTGRES POSTGRES POSTGRES",
#         "hmm"
#     ]
# )

# x = qdrant.search("somebody_once_told_me", embed.embeddings.create("rm -rf /*").data[0].embedding)
# print(x)

# # curl -X POST \
# #      -H "Authorization: Bearer <YOUR_TOKEN>" \
# #      -H "Content-Type: application/json" \
# #      https://llm.t1v.scibox.tech/v1/embeddings \
# #      -d '{
# #            "model": "bge-m3",
# #            "input": "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ –ø—Ä–æ –æ—Å–µ–Ω—å"
# #          }'
